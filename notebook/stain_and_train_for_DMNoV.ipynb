{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48173f7-86d6-40f7-a87f-be38769c4676",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Synthetic Staining and Binary Classification Pipeline\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The purpose of this notebook is to guide you through the process of taking SVS files (or synehtically generated PNGs), synthetically staining a-synuclein proteins and then classifying pathology based on their presence.\n",
    "\n",
    "\n",
    "## Setup\n",
    "The following cell includes the basic Python enviroment requirements. For each step of the process (colourisation, training and validation) the relevent Polygeist module is imported preceeding the relevent example code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff541a7f-4ded-4309-9c0c-be05dc72ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real vs Fake Config\n",
    "is_synthetic = True\n",
    "if is_synthetic:\n",
    "    datadir = \"./Data/fake\"  # Input examples supplied in the repo\n",
    "else:\n",
    "    datadir = \"./Data/real\"  # Not supplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76665641-5a49-4cb0-856b-ad25dde4f536",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# System utilities\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "# Numeric includes and plotting\n",
    "import numpy as np\n",
    "from pqdm.processes import pqdm\n",
    "\n",
    "%matplotlib widget\n",
    "# Image loading\n",
    "import lycon\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Move cwd to project root\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa354747-2563-444c-9f10-1d16c994b390",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configuration (for Staining)\n",
    "We are going to use a pretrained caffe model, that comes with the iDeepColor repository to stain our a-syn.  Below are some configuration parameters that will be used during our staining procedure:\n",
    "\n",
    "`state_path` : This is the location of our caffe model\n",
    "\n",
    "`dump_path_segmented`: This is the path where we will dump each portion (stained window segment) of our images that we stain.\n",
    "\n",
    "`dump_path_full` : This is where we will dump all of our full scale stained images (stitched together from multiple segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f631362a-a8de-4f76-aa05-72fab25884d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Synthetic Staining Procedure\n",
    "\n",
    "Firstly we tumble over our slide, using the `staining_window`.  We produce a conservative binary mask, which will demarcate some a-syn as well as some unwanted cell bodies etc.  This binary mask, and the monochrome slide will be passed to the iDeepColor network, with the intention that it will fill in more a-syn, and will not fill weakly masked bodies (such as the neuromelanin pigmentation).  Each window segment is then resized, and dumped to disk if we detect some staining, as well as being stitched together to produce a full resolution stained slide of all tiles (regardless of staining).\n",
    "![alt text](assets/im1.png \"Colourisation\")\n",
    "\n",
    "We invert our slide (`I_invert = 255 - I`) to make them easier to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38db85c-0909-40f4-967d-344fc60736ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from polygeist.preprocess import colourise_slide_and_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b88cef-5f0e-490f-8b98-a4206d211abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destination location for stained png images\n",
    "# Expecting PD and Control subdirectories to exist\n",
    "dump_path_full = f\"{datadir}/full_stain_dump\"\n",
    "dump_path_segmented = f\"{datadir}/segmented_dump\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f8a7c-9ae3-4707-8e38-6393a741a684",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example configuration for fake data\n",
    "This first configuration is for fake data to allow cursory code testing and dissemination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a61077c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the positive runs and negative runs - EXAMPLE CONFIG FOR FAKE DATA\n",
    "if is_synthetic:\n",
    "    positive_run = glob(f\"{datadir}/input/PD/*.png\")\n",
    "    negative_run = glob(f\"{datadir}/input/Control/*.png\")\n",
    "\n",
    "    # Use all fake slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d61ded",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example configuration for real data - Only use DMNoV\n",
    "For actual slides, we weed our slide names by ID=17, which indicates slides of the Dorsal Nucleus of the Vagus, which has a-syn present for Braak 1+ PD cases, but should not have any present for the control cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2127c53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the positive runs and negative runs- EXAMPLE CONFIG FOR REAL DATA\n",
    "if not is_synthetic:\n",
    "    positive_run = [x for x in glob(f\"{datadir}/input/PD/*.svs\") if \"-17_\" in x]\n",
    "    negative_run = [x for x in glob(f\"{datadir}/input/Control/*.svs\") if \"-17_\" in x]\n",
    "\n",
    "    # Only look at Braak 1, slide 17 for this run (The Slide index is in the filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a494ee-83fb-4054-936e-3b6ad232be14",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run preprocessing on slide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e760a487-058c-4eb8-9640-9e7efee96d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare parameters for colourise_slide_and_segment jobs\n",
    "positive_run_kwargs = [\n",
    "    {\n",
    "        \"slide_file\": x,\n",
    "        \"is_synthetic\": is_synthetic,\n",
    "        \"dump_path_full\": dump_path_full,\n",
    "        \"dump_path_segmented\": dump_path_segmented,\n",
    "        \"subdirectory\": \"PD\",\n",
    "    }\n",
    "    for x in positive_run\n",
    "]\n",
    "\n",
    "negative_run_kwargs = [\n",
    "    {\n",
    "        \"slide_file\": x,\n",
    "        \"is_synthetic\": is_synthetic,\n",
    "        \"dump_path_full\": dump_path_full,\n",
    "        \"dump_path_segmented\": dump_path_segmented,\n",
    "        \"subdirectory\": \"Control\",\n",
    "    }\n",
    "    for x in negative_run\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0fa44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Produce the slide sections, and full stains for the PD and Control groups for Slide 17 (real data).\n",
    "# We set 1 workers here, which can be increased or decreased depending on available compute.\n",
    "# For the real dataset, running time on 3090 (utilisation around 30%), 10 hours.\n",
    "\n",
    "_ = pqdm(\n",
    "    positive_run_kwargs, colourise_slide_and_segment, n_jobs=1, argument_type=\"kwargs\"\n",
    ")\n",
    "_ = pqdm(\n",
    "    negative_run_kwargs, colourise_slide_and_segment, n_jobs=1, argument_type=\"kwargs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6318214",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generating testing and training sets for our filtered patches\n",
    "\n",
    "Our filtered patches will now contain a chunk of legitimate stains, as well as edge cases (from the edge of the slide) and foreign bodies (like mould etc).  We will chunk these into train and test sets.  Note, this needs only to be done once, so this can be skipped if you have already done this previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b877f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now we have our folders, we need to create a training and validation set.\n",
    "# We will use a clean copy of the data for performance, repeatability and safety.\n",
    "training_dump_path = f\"{datadir}/training_dump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c15c86-484f-46ba-bd02-215cd2d78b10",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Should we copy files to create training dataset?\n",
    "# Skip this cell if the data has already been prepared\n",
    "# Do not run twice as it does not remove old datasets.\n",
    "skip = len(glob(f\"{training_dump_path}/train/*/*.png\")) > 0\n",
    "\n",
    "if not skip:\n",
    "    # Splits\n",
    "    prop_data_train = 0.75\n",
    "\n",
    "    # Copy and partition the files (train and val)\n",
    "    for s in [\"Control\", \"PD\"]:\n",
    "        for file in glob(f\"{dump_path_segmented}/{s}/*.png\"):\n",
    "            # basename for dumping out\n",
    "            base = os.path.basename(file)\n",
    "            if random.random() > (1.0 - prop_data_train):\n",
    "                shutil.copyfile(file, f\"{training_dump_path}/train/{s}/\" + base)\n",
    "            else:\n",
    "                shutil.copyfile(file, f\"{training_dump_path}/val/{s}/\" + base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176cd7d-95e7-40ec-8a59-5bb943418ee3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training pipeline\n",
    "\n",
    "We are now all the way to training, we have chunked through our slides, stained, filtered and segmented into training and test sets.  The next steps are to setup our runtime transformations for our training, and actually train our PDNet model.\n",
    "![alt text](assets/im0.png \"Colourisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdb538-acac-435a-a743-4472a5cd3ef1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from polygeist.training import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60bfd42-ce54-4fde-b362-94591378c091",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Our dump path for our model training run, model checkpoints will be saved here\n",
    "model_dump_dir = f\"{datadir}/model_dump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee96626-6cc1-4677-a4fd-0be026f2bb8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start a timer\n",
    "start_time = time.time()\n",
    "\n",
    "latest_model_name = train_model(training_dump_path, model_dump_dir)\n",
    "\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f\"Training complete in {time_elapsed // 60}m {time_elapsed % 60}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b2d33-fd46-4d02-937b-f683f95a69e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Architecture\n",
    "\n",
    "We have loaded our PDNet from our model file, but below we can see a diagram of the architecture, and the parameters we will use to train it.\n",
    "![alt text](assets/im2.png \"Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cafa434-845b-4b70-9051-2109525cef00",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Validation\n",
    "Here we load the model file that we have just trained.  This will be stored in `latest_model_name`.  Below we are using a model that has been previously trained. Again, patches are resized to the network size. We will run a sweep of thresholds instead of using `T > 0` as a boolean classifier.  This will allow us to establish the best threshold for use on our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c76eb-d002-4219-85de-2ac796ef4749",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from polygeist.validation import plot_roc, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ec8a9-dcba-4f1b-863b-d8a170a7365c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now we can run validation, on slide and case level\n",
    "# latest_model_name will have our last model, or it maybe specified manually.\n",
    "# E.g. model_file = f\"{model_dump_dir}/PDNET_checkpoint_490_16_18_48\"\n",
    "model_file = f\"{model_dump_dir}/{latest_model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e50f3-34d9-4829-8680-00eab89f3c4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_data_and_labels = validate(model_file, training_dump_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81559f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs = np.hstack(output_data_and_labels[\"outputs\"])\n",
    "labels = np.hstack(output_data_and_labels[\"labels\"])\n",
    "\n",
    "matched = outputs[labels == 1.0]\n",
    "non_matched = outputs[labels == 0]\n",
    "\n",
    "_, stats = plot_roc(\n",
    "    plt, matched, non_matched, return_stats=True, verbose=False, steps=500000\n",
    ")\n",
    "\n",
    "specification_metric = \"F1\"\n",
    "in_ = np.where(stats[specification_metric] == np.max(stats[specification_metric]))[0][0]\n",
    "print(\n",
    "    f\"Best M({specification_metric}): gives {stats['H'][in_]} hits and {stats['F'][in_]} FAs, S={stats['S'][in_]}, \"\n",
    "    f\"P={stats['P'][in_]},\"\n",
    "    f\" F1={stats['F1'][in_]}, A={stats['A'][in_]}\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513e19a-ee92-4ede-bfbd-143ffe9610f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusions on Training and Validation\n",
    "\n",
    "Below is the performance from our development run of PDNet\n",
    "\n",
    "|              | Hits                 | FAs                   | S                    | P                    | F1                    | A                    |\n",
    "|--------------|----------------------|-----------------------|----------------------|----------------------|-----------------------|----------------------|\n",
    "| Best M(F1)   | 0.9292604501607717   | 0.12290502793296089   | 0.8770949720670391   | 0.8831884998207366   | F0.9056389068818823   | 0.9031777111139054   |\n",
    "\n",
    "Classification is on a per-patch basis, so some aggregation over those patches should yield good classification results per case.  A more conservative threshold should be selected for this task.\n",
    "\n",
    "This work shows that classification is possible, and that there are more frequent and different stains between the PD and control groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f3a02-7a1c-41cc-889f-5d50f39286a7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Example: Marking Regions of Positive Classification\n",
    "\n",
    "As an additional example, we illustrate the utility of the model by iteratating over a fully stained slide and classifing each window, marking any positives as we go. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d34191b-3f32-48be-a28d-422c6ca0c6b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Weeding Results\n",
    "\n",
    "The network was only trained of pre-filtered a-synuclein containing regions, which means that the results on regions which do not contain a-syn marking / highlighting is undefined.\n",
    "\n",
    "We will go over the stained image, see if it was passed to the network and then if it was, we will see what its score was.  If it is greater than 95% confidence, we will mark it in red and the re-encode an image at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392f84d-6d9c-400f-a470-c7ee6ddff1d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from polygeist.example import label_image_with_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9628e-dd99-4d45-b94c-973e176b391e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is the file we will mark with binary results\n",
    "file_to_stain = f\"{datadir}/full_stain_dump/PD/slide_100.png_synthetic_stain.png\"\n",
    "marker_output_path = f\"{datadir}/full_stain_PD_with_regions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352edb36-4026-485f-a4c8-1c8bda75d0d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run the algo using our results that we have just gathered\n",
    "label_image_with_confidence(model_file, file_to_stain, marker_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b38818-81a2-40ad-90bb-b74002e01112",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now lets load the image and view it.\n",
    "annotated = lycon.load(f\"{marker_output_path}/{os.path.basename(file_to_stain)}\")\n",
    "plt.figure()\n",
    "plt.imshow(annotated, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849585c2-5fc5-425a-bdc4-a0771d589829",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
