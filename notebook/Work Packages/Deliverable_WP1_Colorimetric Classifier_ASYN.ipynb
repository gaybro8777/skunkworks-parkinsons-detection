{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea473d8e-1ecc-4192-84d2-d74f8872049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory so 'Polygeist' is in the path.\n",
    "import os\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# OS & Utilities\n",
    "from glob import glob\n",
    "\n",
    "# Maths, Image, Science Libraries\n",
    "import imageio.v3 as io\n",
    "import numpy as np\n",
    "from pqdm.processes import pqdm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Polygeist libraries\n",
    "import polygeist.colour as pc\n",
    "from polygeist.slidecore.slide import (\n",
    "    AperioSlide,\n",
    "    SpectralSlideGenerator,\n",
    "    SyntheticSlide,\n",
    ")\n",
    "from polygeist.training import train_model\n",
    "from polygeist.utils import (\n",
    "    calc_median_score_list,\n",
    "    collect_cases,\n",
    "    load_filenames_and_generate_conditions,\n",
    "    plot_roc,\n",
    "    region_count_score_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb76a5a-1774-40e1-ae67-621282dd0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c04e2-d277-4e39-9319-c4ae8f4ae243",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This workbook explains the core priciples of the colourimetric based segmentation of microscope images.  It loads a number of basis functions for the Aperio L2 Microscope, brain and staining functions, and processes them to produce likely RGB values found within images.  These RGB values in the real images are then estimated for their basis componenets by fitting them to the likely RGB values.\n",
    "\n",
    "This workbook should be threated as an executable record of the development process, for a full workflow, using the library functions, see WP2 onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe491d0-36b5-4089-808d-5fe57f415c59",
   "metadata": {},
   "source": [
    "# Photometric Calibration of the microscope\n",
    "\n",
    "Before we can segment our images for our stained protein, we must determine the sensor response from our microscope; given the integration of our stain transmission spectra, our lightsource, and our sensor sensitivity functions.\n",
    "\n",
    "Here we:\n",
    "* Load the sensitivities of the sensor, the illumination power of the lightsource (by wl) and the transmission of the stains / matter under examination.\n",
    "* Calculate the sensor response array, to be used to decompose a sensor response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polygeist.microscope import Microscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = Microscope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05f080-893e-413f-8d73-5c3812e9ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dab Stain\n",
    "DAB = pc.Illuminant.from_file_with_range(\"spectral/histology/DABL20Vector.csv\", ms.wl)\n",
    "# Hemotoxylin\n",
    "H = pc.Illuminant.from_file_with_range(\"spectral/histology/HemotoxylinC19.csv\", ms.wl)\n",
    "# Eosin\n",
    "E = pc.Illuminant.from_file_with_range(\"spectral/histology//Eosin6um.csv\", ms.wl)\n",
    "# Healthy Brain Absorption\n",
    "_B = pc.Illuminant.from_file_with_range(\n",
    "    \"spectral/histology/HealthyBrainAbsorption9um.csv\", ms.wl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096aaab2-69ae-4131-9c5f-c4421a1fdef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Transmission Function for the brain\n",
    "_B[np.isnan(_B)] = 0\n",
    "B = 1.0 - (_B / np.max(_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b742b896-aacd-4e3a-8f70-26a3ea47facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the array of sensor RGB values for the given spectra\n",
    "responses = np.vstack([ms.response(s) for s in [DAB, H, ms.ls, B, E]])\n",
    "print(responses)\n",
    "\n",
    "# These are sensor specific responses for the brain transmission * filter responses,\n",
    "# for the AT2 sensor and lightsource.\n",
    "# See reports for how to generate them for other sensing systems.\n",
    "\n",
    "# 7.10357511 12.61506218 13.59695489  # DAB\n",
    "# 8.81961536 10.18302502  5.08567669  # Hematoxylin\n",
    "# 11.02074647 15.41804066 12.77042165 # Light Source\n",
    "# 17.05035857 17.64819458  9.17788779 # Brain Transmission\n",
    "# 0.45574971  4.32897163  1.68161384  # Eosin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7007e0c-0957-425c-b407-0ef912687b89",
   "metadata": {},
   "source": [
    "# Example Fit\n",
    "\n",
    "Here we fit our loaded image to the computed functions and display the results.  This uses teh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c9fee-7165-4780-8ba3-cb90186f01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data or use simulated data\n",
    "simulated_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979a467-2e05-4823-b9da-35827415047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your path here if you are not using simulated data!\n",
    "example_slide_path = \"localnas/A-syn cases/PD/PD788/PD788-17_A-syn.svs\"\n",
    "\n",
    "if simulated_data:\n",
    "    image = SpectralSlideGenerator(width=100, height=100).image\n",
    "else:\n",
    "    image = AperioSlide(example_slide_path).get_slide_with_pixel_resolution_in_microns(\n",
    "        2.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a5d34-c3b8-43db-9bfe-d70b695be0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(image.astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe1044-b1ee-417c-9037-fbd41bfad15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the normalisation function we will use to scale within our planes\n",
    "def normalise(F):\n",
    "    F += max(np.abs(F.min()), np.abs(F.max()))\n",
    "    F /= F.max()\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fa2a1-ae82-4eab-b2ab-3d2f6e023f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our image to Nx3 Tristimulus values\n",
    "T_I = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "\n",
    "# Least squares fit to our response functions\n",
    "T_x = np.linalg.lstsq(responses.T, T_I.T, rcond=None)\n",
    "\n",
    "# Normalise our responses per map for DAB and Brain Transmission\n",
    "DAB = normalise(T_x[0][0].copy())\n",
    "BT = normalise(T_x[0][3].copy())\n",
    "\n",
    "raw_DAB = DAB - BT\n",
    "raw_DAB = raw_DAB.reshape(image.shape[0], image.shape[1])\n",
    "\n",
    "_DAB = T_x[0][0].reshape(image.shape[0], image.shape[1])\n",
    "_BT = T_x[0][3].reshape(image.shape[0], image.shape[1])\n",
    "\n",
    "# Values below our raw threshold will be considered A-syn (typically BT has significantly more power)\n",
    "raw_threshold = -0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d3d3d-b858-424e-bb26-d8afdb33c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show our decomposition\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "fig.suptitle(\"Comparisons between Original, Decomposed & Isolated Signals\")\n",
    "axs[0, 0].set_title(\"RGB Image\")\n",
    "axs[0, 0].imshow(image.astype(int))\n",
    "axs[0, 1].set_title(\"DAB Estimate\")\n",
    "axs[0, 1].imshow(normalise(_DAB))\n",
    "axs[1, 0].set_title(\"Brain Transmission Estimate\")\n",
    "axs[1, 0].imshow(normalise(_BT))\n",
    "axs[1, 1].set_title(\"Asyn Isolation\")\n",
    "# Here we threshold the raw DAb signal to get A-syn\n",
    "axs[1, 1].imshow(raw_DAB < raw_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e665640-ee6d-4f01-80e5-7e80cfab6c39",
   "metadata": {},
   "source": [
    "# Example Segmentation of Images Using the Microscope Calibration\n",
    "\n",
    "Below you can see the output matrix of the above calibration can be used to segment a signal we are interested in.  We do this by calculating the linear combination of weightings to produce each observed pixel, given the possible sensor responses.  Then, to isolate the signal of interest (DAB), we can subtract a uniform signal (Brain Tissue), to produce just the stain response.  We will segment the brain slides and produce densities and JPEGs of the areas in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb712f9-26a2-4fad-9c77-5e88bd27d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # The threshold level in RGB to use for our prexisting RGB thresholding routines from Phase 1\n",
    "    \"B_channel_threshold\": 20,\n",
    "    # This is where we will be storing our segmeneted data\n",
    "    \"dump_path\": \"/run/media/brad/ScratchM2/maps_dump_512_jpeg/\",  # maps_dump_512_jpeg\n",
    "    # This is our window size, over which we will iterate.\n",
    "    \"map_stride\": 512,\n",
    "    # Our negative cases, our controls, are stored in the 'Controls' folder\n",
    "    \"negative_case_folder\": \"Controls\",\n",
    "    # Our positive, pd cases, are stored in the 'PD' folder\n",
    "    \"positive_case_folder\": \"PD\",\n",
    "    # Other search paths to look for cases\n",
    "    \"search_directories\": [\n",
    "        \"/run/media/brad/TBSSD1/A-syn cases/\",\n",
    "        \"/run/media/brad/TBSSD2/A-syn cases/\",\n",
    "    ],\n",
    "    # These are our case filenames\n",
    "    \"case_files\": \"Data/filenames/asyn_files.txt\",\n",
    "    # For use with real data, this filters slides with the wrong index\n",
    "    \"slide_index_filter\": \"17_A\",\n",
    "    # Toggle this is you are using simulated data\n",
    "    \"simulated\": simulated_data,\n",
    "    # Number to simulate\n",
    "    \"simulation_n\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a34e84c-fc97-4d68-a191-58d64152daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_decompose_and_dump_jpeg(\n",
    "    slice,\n",
    "    stride=1000,\n",
    "    process_raw=True,\n",
    "    threshold=0.175,\n",
    "    pc=0.0375,\n",
    "    raw_threshold=-0.3,\n",
    "    raw_pc=0.00125,\n",
    "    jpeg_dump_path_and_name=\"start_name\",\n",
    "):\n",
    "\n",
    "    # These are sensor specific responses for the brain transmission * filter responses, for the AT2 sensor\n",
    "    # and lightsource.  See reports for how to generate them for other sensing systems\n",
    "    responses = np.array(\n",
    "        np.matrix(\n",
    "            \"[ 7.10357511 12.61506218 13.59695489 ; \"  # DAB\n",
    "            \"8.81961536 10.18302502  5.08567669; \"  # Hematoxylin\n",
    "            \"11.02074647 15.41804066 12.77042165 ; \"  # Light Source\n",
    "            \"17.05035857 17.64819458  9.17788779; \"  # Brain Transmission\n",
    "            \"0.45574971  4.32897163  1.68161384]\"\n",
    "        )\n",
    "    )  # Eosin\n",
    "\n",
    "    # Get slide at native resolution\n",
    "    image = slice.get_slide_with_pixel_resolution_in_microns(2.0)\n",
    "\n",
    "    # Get the height and width of the slice\n",
    "    yy, xx, _ = image.shape\n",
    "\n",
    "    # Create a densities array to store the local densities\n",
    "    x_pass = int(np.ceil(xx / stride))\n",
    "    y_pass = int(np.ceil(yy / stride))\n",
    "    densities = np.zeros((y_pass, x_pass))\n",
    "\n",
    "    # Convert our image to Nx3 Tristimulus values\n",
    "    T_I = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "\n",
    "    # Least squares fit to our response functions\n",
    "    T_x = np.linalg.lstsq(responses.T, T_I.T, rcond=None)\n",
    "\n",
    "    # Normalise our reponses per map for DAB and Brain Transmission\n",
    "    DAB = normalise(T_x[0][0].copy())\n",
    "    BT = normalise(T_x[0][3].copy())\n",
    "\n",
    "    # Remove the background (Brain) fom DAB response, leaving just the dab mask\n",
    "    # Remove the background (Brain) fom DAB response, leaving just the dab mask\n",
    "    if process_raw:\n",
    "        raw_DAB = DAB - BT\n",
    "        raw_DAB = raw_DAB.reshape(image.shape[0], image.shape[1])\n",
    "    else:\n",
    "        mDAB = colourmap_1d(np.array([1.0, 1.0, 0.0]), np.array([0.0, 0.0, 1.0]), DAB)\n",
    "        mBT = colourmap_1d(np.array([1.0, 1.0, 0.0]), np.array([0.0, 0.0, 1.0]), BT)\n",
    "        m_DAB = mDAB - mBT\n",
    "        raw_DAB = m_DAB.reshape(image.shape[0], image.shape[1], 3)\n",
    "\n",
    "    # ticker for JPEG index\n",
    "    dump_number = 0\n",
    "    if not process_raw:\n",
    "        # Tumble over the slice using a fixed window size\n",
    "        for xi, x in enumerate(np.arange(0, xx, stride)):\n",
    "            for yi, y in enumerate(np.arange(0, yy, stride)):\n",
    "                # Grab this section x -> x + stride, y -> y + stride\n",
    "                section = raw_DAB[y : y + stride, x : x + stride]\n",
    "\n",
    "                diff = np.abs(\n",
    "                    section[:, :, 0].astype(float) - section[:, :, 2].astype(float)\n",
    "                )\n",
    "                if np.sum(diff > threshold) / (stride**2) > pc:\n",
    "                    io.imwrite(\n",
    "                        f\"{jpeg_dump_path_and_name}{dump_number}.jpg\",\n",
    "                        image[y : y + stride, x : x + stride, :],\n",
    "                    )\n",
    "                    dump_number += 1\n",
    "    else:\n",
    "        # Tumble over the slice using a fixed window size\n",
    "        for xi, x in enumerate(np.arange(0, xx, stride)):\n",
    "            for yi, y in enumerate(np.arange(0, yy, stride)):\n",
    "                # Grab this section x -> x + stride, y -> y + stride\n",
    "                section = raw_DAB[y : y + stride, x : x + stride] < raw_threshold\n",
    "\n",
    "                if np.mean(section) > raw_pc:\n",
    "                    io.imwrite(\n",
    "                        f\"{jpeg_dump_path_and_name}{dump_number}.jpg\",\n",
    "                        image[y : y + stride, x : x + stride, :],\n",
    "                    )\n",
    "                    dump_number += 1\n",
    "    return densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910b19e-e380-42e9-bd84-324bd252b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This process function will be called in parallel on each slide.\n",
    "def process(argv):\n",
    "    file = argv[\"file\"]\n",
    "    cnd = argv[\"condition\"]\n",
    "    simulated = argv[\"sim\"]\n",
    "\n",
    "    try:\n",
    "        file_name = os.path.basename(os.path.normpath(file))\n",
    "        slide = AperioSlide(file) if not simulated else SyntheticSlide(file)\n",
    "    except:\n",
    "        return file\n",
    "    d = spectral_decompose_and_dump_jpeg(\n",
    "        slide,\n",
    "        stride=config[\"map_stride\"],\n",
    "        jpeg_dump_path_and_name=f'{config[\"dump_path\"]}/{cnd}/{file_name}',\n",
    "    )\n",
    "    with open(f'{config[\"dump_path\"]}/{cnd}/{file_name}.npy', \"wb\") as f:\n",
    "        np.save(f, d)\n",
    "\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61fdf90-3d87-4ef7-8ba2-da10cb99979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the directory structure to save our files\n",
    "for pth in [config[\"positive_case_folder\"], config[\"negative_case_folder\"]]:\n",
    "    pathlib.Path(config[\"dump_path\"] + pth).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "files_list_and_configuration = []\n",
    "# For each case in positive/negative case directories, or for simulated data\n",
    "if not config[\"simulated\"]:\n",
    "    for cases in [config[\"positive_case_folder\"], config[\"negative_case_folder\"]]:\n",
    "        for searched_path in config[\"search_directories\"]:\n",
    "            for p in glob(searched_path + cases + \"/*/\", recursive=True):\n",
    "                for f in glob(p + \"/*.svs\", recursive=True):\n",
    "                    if config[\"slide_index_filter\"] in f:\n",
    "                        files_list_and_configuration.append(\n",
    "                            {\n",
    "                                \"file\": f,\n",
    "                                \"condition\": cases,\n",
    "                                \"sim\": False,\n",
    "                            }\n",
    "                        )\n",
    "else:\n",
    "    for i in np.arange(0, config[\"simulation_n\"]):\n",
    "        # Which condition to generate, PD or Control\n",
    "        condition = (\n",
    "            config[\"positive_case_folder\"]\n",
    "            if np.random.random() > 0.5\n",
    "            else config[\"negative_case_folder\"]\n",
    "        )\n",
    "        # We will use the dataset name conv for our slides.\n",
    "        name_for_slide = \"PD\" if \"PD\" in condition else \"PDC\"\n",
    "        # Generate a new slide and save it to disk\n",
    "        SpectralSlideGenerator(\n",
    "            512 * 4,\n",
    "            512 * 4,\n",
    "            filename=f\"{config['dump_path']}/{name_for_slide}{i}-17_A.png\",\n",
    "            control=\"C\" in name_for_slide,\n",
    "        )\n",
    "        # Append and continue\n",
    "        files_list_and_configuration.append(\n",
    "            {\n",
    "                \"file\": f\"{config['dump_path']}/{name_for_slide}{i}-17_A.png\",\n",
    "                \"condition\": condition,\n",
    "                \"sim\": True,\n",
    "            }\n",
    "        )\n",
    "\n",
    "result = pqdm(\n",
    "    files_list_and_configuration, process, n_jobs=1\n",
    ")  # 1 job for AJAX optimistion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99794e1f-ef2f-43d6-9f6e-2ba71db870f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_conditions = load_filenames_and_generate_conditions(config[\"case_files\"])\n",
    "\n",
    "positive_cases = []\n",
    "negative_cases = []\n",
    "for case, condition in case_conditions.items():\n",
    "    positive_cases.append(case) if \"C\" not in condition else negative_cases.append(case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd27b3-b315-420b-84f7-6cf6bc1b15c5",
   "metadata": {},
   "source": [
    "# Raw Analysis of Density Maps\n",
    "\n",
    "Let's first just take a look at the density maps that have been dumped.  We are going to use the basic thresholding routines to determine if we have successfully segmented asyn, before we \n",
    "look into more advanced classifications methods in the other WPs.\n",
    "\n",
    "Process:\n",
    "\n",
    "* Create histograms of the density for each case, and band pass those densities to highlight the maximal differences between the groups.\n",
    "* Calculate the mean bandpass density for each 'case', and then produce an ROC on the basis of those densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab750842-9df7-440f-a656-284e432c4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use a simple median classifier, with a low RGB threshold as a simple mask.\n",
    "# Note this is for illustrative purposes,\n",
    "# we are going to explore a better classification method in the following workbooks.\n",
    "\n",
    "# Count results of simple median classifier\n",
    "positive_score_list = calc_median_score_list(\n",
    "    positive_cases,\n",
    "    f'{config[\"dump_path\"]}/{config[\"positive_case_folder\"]}/*17_*.jpg',\n",
    "    rgb_threshold=config[\"B_channel_threshold\"],\n",
    ")\n",
    "\n",
    "negative_score_list = calc_median_score_list(\n",
    "    negative_cases,\n",
    "    f'{config[\"dump_path\"]}/{config[\"negative_case_folder\"]}/*17_*.jpg',\n",
    "    rgb_threshold=config[\"B_channel_threshold\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57199fc-79f4-4e8c-8497-2291135a4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plot_roc(\n",
    "    np.array(positive_score_list),\n",
    "    np.array(negative_score_list),\n",
    "    verbose=False,\n",
    "    title=\"Threshold of Median Scores Per Case ROC Curve\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb40a8-604d-41de-8c01-e4f0aee3e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the median Counts\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot([negative_score_list, positive_score_list], showfliers=False)\n",
    "ax.set_xticks([1, 2], [\"Control\", \"PD\"])\n",
    "plt.xlabel(\"Condition\")\n",
    "plt.ylabel(\"Quartiles of ROIs Identified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75326b80-118b-475b-a283-a99683c236a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.hstack(\n",
    "    [np.ones(len(positive_score_list)), np.zeros(len(negative_score_list))]\n",
    ")\n",
    "outputs = np.hstack([positive_score_list, negative_score_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba51186-0348-4a63-89ef-bdbc53d774dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(labels, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03a945-079d-4f25-a942-7aa5132238c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"PD vs Control\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Alarm Rate\", fontsize=18)\n",
    "plt.ylabel(\"Hit Rate\", fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "# plt.title(\"512um Patch Level Discrmination between Taupathology and Control Tau Segmentation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76720d50-1011-48b2-b3cd-af0398464c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptives(scores):\n",
    "    px = 512**2\n",
    "    mu = np.median(scores)\n",
    "    p95 = np.percentile(scores, 95)\n",
    "    print(f\"mu : {(mu / px)*100}, 95pc: {(p95 / px)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ba4fc-68f8-4540-a129-986759862a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives(negative_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9dce7-f7d2-4d25-8d19-ca2da492bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives(positive_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead81f7-cd8e-4470-a849-cca004814d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
