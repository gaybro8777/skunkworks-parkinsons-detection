{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df89ed-0470-4d42-bf17-ddf5b5d1f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d828ff-001a-4acb-8b57-3a32c9668bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from polygeist.label import process_files_and_folders\n",
    "from polygeist.training import train_model\n",
    "from polygeist.utils import (\n",
    "    SegmentationFilesDirectoryHandler,\n",
    "    load_filenames_and_generate_conditions,\n",
    ")\n",
    "from polygeist.validation import validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6392159-5c2e-46f5-aef2-300ca7b9fc0c",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This workbook will process the Tau SVS slide files, producing regions of interest (ROIs) as jpegs for classification using the PDNet CNN.  Because Tau pathology exists in controls, we will be principally be discrimination between morphology; that is, Tau shape, colour and size in the segmented regions in control and pathology cases.\n",
    "\n",
    "We will:\n",
    "\n",
    "- Search through the data directory with `polygeist.label`, which will process our SVS files and produce ROIs for classification.\n",
    "- Segment those ROIs into training and test sets for use with PDNet\n",
    "- Run the PDNet training routine on those training images\n",
    "- Validate the model by loading it and running it on the validate dataset\n",
    "- Use `sklearn.metrics` to evaluate our model, and plot an ROC function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011fc41-746b-4e7f-a34f-a299a5291a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This configuration defines what we need to know about the slides and where to put the outputs, we also place the protein specific information\n",
    "# for Tau here.\n",
    "config = {\n",
    "    # This is where the SVS slides are stored\n",
    "    \"svs_data_location\": \"/home/brad/localnas/\",\n",
    "    # This is the directory where all our segmentations, model files and sets will be stored\n",
    "    \"working_root\": \"/run/media/brad/ScratchM2/Tau_label_dump_256/\",\n",
    "    # These are our case filenames, which we shall parse to ensure case level segmenting in training and test\n",
    "    \"case_files\": \"Data/filenames/tau_files.txt\",\n",
    "    # Segmentation Specific Information\n",
    "    # This is the stride over which we will look (the window size)\n",
    "    \"stride\": 256,\n",
    "    # The PUK set contains ID-INDEX_Protein in the filename, so here we specify 10_Tau (only use slide 10)\n",
    "    \"index\": \"10_Tau\",\n",
    "    # This is the threshold under which a DAB activation will be considered noise\n",
    "    \"raw_threshold\": -0.1,\n",
    "    # This is the amount of pixels (as a percentage) per region that have to be activated to define a ROI\n",
    "    \"class_threshold\": 0.025,\n",
    "    # PDNET Configuration\n",
    "    \"batch_size\": 32,  # Adjust for memory constraints (may affect results)\n",
    "    \"num_epochs\": 500,  # Adjust for time available for training (may affect results)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc5161-1928-4535-88c0-393a0347a16f",
   "metadata": {},
   "source": [
    "# Spectral Estimation & Segmentation\n",
    "\n",
    "This process utility (from `polygeist.label`) takes a list of protein specific parameters and performs the spectral estimation technique to produce estimates of the DAB staining.  It then segments ROIs with specific parameters and dumps them to disk as jpegs for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f1173-3e72-44a1-920d-6204cd3d3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_files_and_folders(\n",
    "    # The input data folder, this is where the SVS files are located\n",
    "    config[\"svs_data_location\"],\n",
    "    # Where we would like to dump the segmentations, and json files\n",
    "    config[\"working_root\"],\n",
    "    # This is the stride over which we will look (the window size)\n",
    "    stride=config[\"stride\"],\n",
    "    # This is the threshold under which a DAB activation will be considered noise\n",
    "    raw_threshold=config[\"raw_threshold\"],\n",
    "    # This is the amount of pixels (as a percentage) per region that have to be activated to define a ROI\n",
    "    class_threshold=config[\"class_threshold\"],\n",
    "    # Do not output full res density images\n",
    "    output_density=False,\n",
    "    # Output json metadata & density information\n",
    "    output_json=True,\n",
    "    # Skip outputting whole JPEGs\n",
    "    skip_jpeg=True,\n",
    "    # Automatically remove the slide background (note this is specialised to PUK Brain Slide Protocol)\n",
    "    auto_remove_background=True,\n",
    "    # Include only slides with 10_Tau in their name, this is slide index 10, Tau labelling\n",
    "    include_only_index=config[\"index\"],\n",
    "    # Output each ROI as a JPEG for CNN training (and obs)\n",
    "    output_segmentation=True,\n",
    "    # Please provide print feedback on processing\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a113eb8-4761-402f-b449-3fad1ddc9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the cases and our conditions for each\n",
    "case_conditions = load_filenames_and_generate_conditions(config[\"case_files\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8f4a1-175f-47ee-85e3-bba502a853b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformly split conditions\n",
    "def split_cases_into_train_and_test(case_cond, condition):\n",
    "    train = []\n",
    "    test = []\n",
    "    switch = False\n",
    "    for key, value in case_cond.items():\n",
    "        if condition not in value:\n",
    "            continue\n",
    "        if switch:\n",
    "            train.append(key)\n",
    "        else:\n",
    "            test.append(key)\n",
    "        switch = not switch\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218217dd-f7d8-4596-965b-52b8a3bf74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train, pd_test = split_cases_into_train_and_test(case_conditions, \"PD\")\n",
    "con_train, con_test = split_cases_into_train_and_test(case_conditions, \"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85bdd8-c2be-49aa-80a6-a2e9c393659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_handler = SegmentationFilesDirectoryHandler(config[\"working_root\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef6722-faaa-4031-a8d3-a85bf1225fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_handler.make_train_and_validation_folders_for_conditions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8c60f-d1d4-42ca-a27f-9bf756e9de20",
   "metadata": {},
   "source": [
    "# Sorting Data into Training and Test\n",
    "\n",
    "Here we sort all regions into either training or test sets, we balance by the N images in the PD condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855a536-3802-48ee-bc04-2ee332c06c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_handler.split_and_copy_root_data_to_train_and_validation(\n",
    "    case_filter_for_train=pd_train, condition=\"PD\", training=True\n",
    ")\n",
    "files_handler.split_and_copy_root_data_to_train_and_validation(\n",
    "    case_filter_for_train=con_train, condition=\"Controls\", training=True\n",
    ")\n",
    "files_handler.split_and_copy_root_data_to_train_and_validation(\n",
    "    case_filter_for_train=pd_test, condition=\"PD\", training=False\n",
    ")\n",
    "files_handler.split_and_copy_root_data_to_train_and_validation(\n",
    "    case_filter_for_train=con_test, condition=\"Controls\", training=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3541c-ac49-4406-a6fb-950fa114f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dump path for our model training run, model checkpoints will be saved here\n",
    "model_dump_dir = f\"{config['working_root']}/model_dump/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d09c16-b440-442e-8b1d-05bf170809e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use a clean copy of the data for performance, repeatability and safety.\n",
    "training_dump_path = files_handler.root + \"/test_partitioned_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6550e-c7fd-4b1a-a751-61a33ca17f8b",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "The data layout is passed to the train_model utility to produce us a PDNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c95ca-0321-4ef7-8c5d-823bcc948080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't inject into the validation set, that is kept clean for validation of the colourimetric segmentation.\n",
    "\n",
    "# Start a timer\n",
    "start_time = time.time()\n",
    "\n",
    "latest_model_name = train_model(\n",
    "    training_dump_path,\n",
    "    model_dump_dir,\n",
    "    config[\"batch_size\"],\n",
    "    config[\"num_epochs\"],\n",
    "    strict=False,\n",
    ")\n",
    "\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f\"Training complete in {time_elapsed // 60}m {time_elapsed % 60}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60138f33-70c2-4482-aff4-b5f5572adb9e",
   "metadata": {},
   "source": [
    "# Model Validation\n",
    "\n",
    "The data layout is passed to the validation utility to produce us validation scores.  Here we load up the last checkpoint file, I have left it hard code, so make sure you change the name to the model file that you have generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8514950a-f20d-422c-82cf-26562c9ab355",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_model_name = f\"PDNET_checkpoint_490_03_06_05\"\n",
    "# Now we can run validation, on slide and case level\n",
    "# latest_model_name will have our last model, or it maybe specified manually.\n",
    "# E.g. model_file = f\"{model_dump_dir}/PDNET_checkpoint_490_16_18_48\"\n",
    "model_file = f\"{model_dump_dir}/{latest_model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c67a9-1d8c-48da-85ca-10dff5112b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_and_labels = validate(model_file, training_dump_path, config[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39809d3e-0ce7-4c86-9ba9-1da39fd81d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.hstack(output_data_and_labels[\"outputs\"])\n",
    "labels = np.hstack(output_data_and_labels[\"labels\"])\n",
    "\n",
    "matched = outputs[labels == 1.0]\n",
    "non_matched = outputs[labels == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf94c8-10ce-4577-ad24-fb4f5208d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(labels, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20668433-7152-4ccd-bf30-9faff076520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"Taupathology vs Control\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Alarm Rate\", fontsize=18)\n",
    "plt.ylabel(\"Hit Rate\", fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "# plt.title(\"512um Patch Level Discrmination between Taupathology and Control Tau Segmentation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac592391-510e-461b-ab12-4e5125279547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an index for the threshold\n",
    "th = 60\n",
    "print(f\"Threshold = {thresholds[th]}, TP : {tpr[th]}, FP {fpr[th]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f918ddb-2b71-4b6f-82e3-60a69ee008e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "t = thresholds[th]\n",
    "N_0 = len(outputs[labels == 0])\n",
    "N_1 = len(outputs[labels == 1])\n",
    "conf = [\n",
    "    (np.sum(outputs[labels == 0] < t) / N_0, np.sum(outputs[labels == 0] >= t) / N_0),\n",
    "    (np.sum(outputs[labels == 1] < t) / N_1, np.sum(outputs[labels == 1] >= t) / N_1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06194d4a-7ab1-43eb-8880-5cc5154cc47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print(\"\".ljust(10), \"Control\".ljust(10), \"Path\".ljust(10))\n",
    "print(\"Control\".rjust(10), f\"{conf[0][0]:.4f}\".ljust(10), f\"{conf[0][1]:.4f}\".ljust(10))\n",
    "print(\"Path\".rjust(10), f\"{conf[1][0]:.4f}\".ljust(10), f\"{conf[1][1]:.4f}\".ljust(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
