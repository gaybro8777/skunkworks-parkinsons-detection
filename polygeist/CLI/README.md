## CLI

The CLI scripts provide a command line interface to the python tools.

These scripts assume a folder structure as encapsulated in docs/datadir.tar
With the folder Data/real containing .svs slide data in input subdirectories (PD and Control).

## CLI Execution
### preprocess.py
The purpose of this script is to process svs slide data prior to training and validation.
This script will synthetically stain slide data and filter the results.
A full size image (png) is created along with any tile segments that pass a colour filter (indicating the presence of evidence for PD).
The script should be called from the project root directory.
Multiple files can be sent for processing (in parallel) using standard Linux commands, e.g.

```shell
ls Data/real/input/PD/*.svs | \
  xargs -I input_arg -n 1 -P 2 \
  python polygeist/CLI/preprocess.py \
    --input_slide input_arg \
    --output_path_full Data/real/full_stain_dump \
    --output_path_segmented Data/real/segmented_dump \
    --subdirectory PD
```
Or, for synthetic (.png) slide files add the '--is_synthetic' flag:
```shell
ls Data/fake/input/PD/*.png | \
  xargs -I input_arg -n 1 -P 2 \
  python polygeist/CLI/preprocess.py \
    --input_slide input_arg \
    --is_synthetic \
    --output_path_full Data/fake/full_stain_dump \
    --output_path_segmented Data/fake/segmented_dump \
    --subdirectory PD
```
And similarly for Control slides (e.g. Data/real/input/Control)

### train_model.py
This script trains the classifier to distinguish between Control and PD slide patches.
The script expects 'train' and 'val' folders each with 'Control' and 'PD' subdirectories*.
A weights checkpoint file is generated that can be subsequently used with the classifier.
The script should be called from the project root directory.
```shell
python polygeist/CLI/train_model.py \
  --training_dump_path Data/real/training_dump \
  --model_dump_dir Data/real/model_dump \
  --batch_size 32 \
  --num_epochs 500
```
An example script for partitioning into training and validation subsets is provided in the accompanying notebook. Alternatively, standard Linux commands can be used, e.g.
```shell
# Copy all segmented Control pngs into the Control training folder
cp Data/real/segmented_dump/Control/*.png Data/real/training_dump/train/Control

# Move a number (e.g. 25%, in this example '3') of files into the validation directory
ls Data/real/training_dump/train/Control/*.png | \
  shuf -n 3 | \
  xargs -I input_arg -n 1 \
  mv input_arg Data/real/training_dump/val/Control
```
And similarly for the PD class.

### validate_model.py
This file produces summary performance statistic for the classifier model (and optionally a ROC image file).
Similar to the training script, this script expects a 'val' subdirectory containing 'Control' and 'PD'.
A weights checkpoint file is also required (e.g. as generated by the train_model.py script).
The script should be called from the project root directory, e.g.
```shell
python polygeist/CLI/validate_model.py \
  --model_file Data/real/model_dump/PDNET_checkpoint_X_XX_XX_XX \
  --training_dump_path Data/real/training_dump \
  --roc_file roc_image.png \
  --batch_size 32
```

## Additional
In addition to the CLI tool set, a script is supplied for creating fake slide data (.png). The script should be called from the project root directory.
### create_fake_slide_dataset.py
To generate slides (.png) with a high likelihood of PD features:
```shell
python polygeist/CLI/create_fake_slide_dataset.py \
  --output_path Data/fake/input/PD \
  --seed_start 100 \
  --quantity 10
```
Or, for Control slides (.png), add the '--is_control' flag:
```shell
python polygeist/CLI/create_fake_slide_dataset.py \
  --output_path Data/fake/input/Control \
  --seed_start 200 \
  --quantity 10 \
  --is_control
```
